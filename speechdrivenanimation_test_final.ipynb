{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import base64\n",
    "import time\n",
    "import wave\n",
    "import sda\n",
    "import torch\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import IPython\n",
    "\n",
    "import houndify\n",
    "from ipywebrtc import VideoStream, AudioRecorder, CameraStream, AudioStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.insert(1, '../speech-driven-animation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9025c4b9a4642039f16f0cf35320191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CameraStream(constraints={'facing_mode': 'user', 'audio': True, 'video': {'width': 640, 'height': 480}})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "camera = CameraStream(constraints=\n",
    "                      {'facing_mode': 'user',\n",
    "                       'audio': True,\n",
    "                       'video': { 'width': 640, 'height': 480 }\n",
    "                       })\n",
    "camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384ac777cd564c7f8440a90a97ea6665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AudioRecorder(audio=Audio(value=b'', format='webm'), stream=CameraStream(constraints={'facing_mode': 'user', 'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "recorder = AudioRecorder(stream=camera)\n",
    "recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No data, did you record anything?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f9d9544be8fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# save output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output.wav\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# will save to test.mp3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# convert to proper wav file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/ipywebrtc/webrtc.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No data, did you record anything?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No data, did you record anything?"
     ]
    }
   ],
   "source": [
    "# save output\n",
    "recorder.save(\"output.wav\")  # will save to test.mp3\n",
    "\n",
    "# convert to proper wav file\n",
    "x,_ = librosa.load('output.wav', sr=16000)\n",
    "sf.write('tmp.wav', x, 16000)\n",
    "wave.open('tmp.wav','r')\n",
    "\n",
    "CLIENT_ID = \"Rco-d2ARwyAUSvklEH_ePg==\"\n",
    "CLIENT_KEY = \"V6TzSgIOkx0CW4AkBSxgLNrcHMEZ26PSB4uLaG-n8t6PsjZSEzBF-aGfXQv-mWXha0_grVB-TO5MGdKhx9XNFA==\"\n",
    "AUDIO_FILE = \"tmp.wav\"\n",
    "\n",
    "BUFFER_SIZE = 256\n",
    "\n",
    "audio = wave.open(AUDIO_FILE)\n",
    "if audio.getsampwidth() != 2:\n",
    "  print(\"%s: wrong sample width (must be 16-bit)\" % fname)\n",
    "  sys.exit()\n",
    "if audio.getframerate() != 8000 and audio.getframerate() != 16000:\n",
    "  print(\"%s: unsupported sampling frequency (must be either 8 or 16 khz)\" % fname)\n",
    "  sys.exit()\n",
    "if audio.getnchannels() != 1:\n",
    "  print(\"%s: must be single channel (mono)\" % fname)\n",
    "  sys.exit()\n",
    "\n",
    "\n",
    "audio_size = audio.getnframes() * audio.getsampwidth()\n",
    "audio_duration = audio.getnframes() / audio.getframerate()\n",
    "chunk_duration = BUFFER_SIZE * audio_duration / audio_size\n",
    "\n",
    "\n",
    "#\n",
    "# Simplest HoundListener; just print out what we receive.\n",
    "# You can use these callbacks to interact with your UI.\n",
    "#\n",
    "class MyListener(houndify.HoundListener):\n",
    "  def onPartialTranscript(self, transcript):\n",
    "    print(\"Partial transcript: \" + transcript)\n",
    "  def onFinalResponse(self, response):\n",
    "    #print(\"Final response: \" + str(response))\n",
    "    \n",
    "    response_bytes = response[\"AllResults\"][0][\"ResponseAudioBytes\"]\n",
    "#     os.system(\"say {}\".format(response_text)) \n",
    "#     print(\"Response bytes:\" + response_bytes)\n",
    "    print(\"Final response: \" + str(response[\"AllResults\"][0][\"SpokenResponse\"]))\n",
    "\n",
    "    # convert bytes string to binary\n",
    "    decoded = base64.decodebytes(response_bytes.encode(\"ascii\"))\n",
    "\n",
    "    # writes response to wav file\n",
    "    with open('myfile.wav', mode='wb') as f:\n",
    "      f.write(decoded)\n",
    "    \n",
    "#     va = sda.VideoAnimator(gpu=0, model_path=\"timit\")# Instantiate the animator\n",
    "#     vid, aud = va(\"IMG_9997.bmp\", \"myfile.wav\")\n",
    "#     va.save_video(vid, aud, \"generated_sabrina.mp4\")\n",
    "      \n",
    "    \n",
    "  def onError(self, err):\n",
    "    print(\"Error: \" + str(err))\n",
    "\n",
    "\n",
    "client = houndify.StreamingHoundClient(CLIENT_ID, CLIENT_KEY, \"test_user\", enableVAD=False)\n",
    "client.setLocation(37.388309, -121.973968)\n",
    "client.setSampleRate(audio.getframerate())\n",
    "client.setHoundRequestInfo(\"ResponseAudioVoice\", \"Sharon\")\n",
    "client.setHoundRequestInfo(\"ResponseAudioShortOrLong\", \"Short\")\n",
    "\n",
    "client.start(MyListener())\n",
    "\n",
    "while True:\n",
    "  chunk_start = time.time()\n",
    "\n",
    "  samples = audio.readframes(BUFFER_SIZE)\n",
    "  if len(samples) == 0: break\n",
    "  if client.fill(samples): break\n",
    "\n",
    "result = client.finish() # returns either final response or error\n",
    "IPython.display.Audio(\"myfile.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'video2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-01166513332b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvideo2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'video2' is not defined"
     ]
    }
   ],
   "source": [
    "# open video\n",
    "video2 = VideoStream.from_url('generated_sabrina.mp4')\n",
    "video2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
